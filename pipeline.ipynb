{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install keybert"
      ],
      "metadata": {
        "id": "_BvuOYFERGq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "from keybert import KeyBERT"
      ],
      "metadata": {
        "id": "BV8rtQOpkYAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = 0\n",
        "query_term = 'redox flow battery'\n",
        "query_term = '%22' + query_term + '%22'\n",
        "query_term.replace(' ', '%20')\n",
        "\n",
        "bulk_data_api_url = f\"https://developer.uspto.gov/ibd-api/v1/application/publications?searchText={query_term}&start={start}&largeTextSearchFlag=Y\"\n",
        "bulk_search = requests.get(bulk_data_api_url).json()\n",
        "\n",
        "result_count = bulk_search['recordTotalQuantity']\n",
        "l = []\n",
        "while start < result_count:\n",
        "  bulk_data_api_url = f\"https://developer.uspto.gov/ibd-api/v1/application/publications?searchText={query_term}&start={start}&largeTextSearchFlag=Y\"\n",
        "  bulk_search = requests.get(bulk_data_api_url).json()\n",
        "  bulk_search_results = bulk_search['results']\n",
        "\n",
        "  for result in bulk_search_results:\n",
        "    d = {}\n",
        "    d['App_Number'] = result['patentApplicationNumber']\n",
        "    d['Base_Pub_Number'] = result['publicationDocumentIdentifier']\n",
        "    d['Base_Abstract'] = result['abstractText'][0]\n",
        "\n",
        "    try:\n",
        "      d['Base_Claims'] = result['claimText'][0]\n",
        "    except:\n",
        "      d['Base_Claims'] = result['claimText']\n",
        "\n",
        "    l.append(d)\n",
        "\n",
        "  start += 100\n",
        "\n",
        "df = pd.DataFrame(l)\n",
        "df = df[df['Base_Claims'].notnull()].reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1qyc_7UKkmgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2text_generator = pipeline(\"text2text-generation\")\n",
        "\n",
        "COMMON_COUNTRY_CODES = ['US', 'JP', 'EP', 'WO', 'CN']\n",
        "COMMON_KIND_CODES = ['A', 'A1', 'A2', 'B1', 'B2']\n",
        "def clean_pub_num(n, debug=False):\n",
        "  n = n.replace('/', '')\n",
        "  n = n.replace(',', '')\n",
        "  n = n.replace('-', '')\n",
        "\n",
        "  spl_n = n.split(' ')\n",
        "  temp_n = ''\n",
        "  for spl in spl_n:\n",
        "    if spl in COMMON_COUNTRY_CODES or spl.isnumeric() or spl in COMMON_KIND_CODES:\n",
        "      temp_n += spl\n",
        "    elif (spl[:-1].isnumeric() and spl[-1] in COMMON_KIND_CODES) or (spl[:-2].isnumeric() and spl[-2:] in COMMON_KIND_CODES):\n",
        "      temp_n += spl\n",
        "\n",
        "  if len(temp_n) < 7 or len(temp_n) > 15:\n",
        "    if debug:\n",
        "      print(temp_n)\n",
        "    return np.nan\n",
        "  else:\n",
        "    return temp_n\n",
        "\n",
        "def clean_whitespace(s):\n",
        "  s = s.replace('  \\n', '')\n",
        "  s = s.replace('\\n', '')\n",
        "  s = s.replace('  ', ' ')\n",
        "  return s\n",
        "\n",
        "def is_valid_char(c):\n",
        "  uni_c = ord(c)\n",
        "  return uni_c > 31 and uni_c < 127\n",
        "\n",
        "def scrape_google_patents(pub_num, debug=False):\n",
        "  country_codes = [''] + COMMON_COUNTRY_CODES\n",
        "  for country_code in country_codes:\n",
        "      temp_num = country_code + pub_num\n",
        "      url = f\"https://patents.google.com/patent/{temp_num}/en\"\n",
        "      page = requests.get(url)\n",
        "\n",
        "      if page.status_code == 404:\n",
        "        continue\n",
        "      else:\n",
        "        parser = BeautifulSoup(page.content, \"html.parser\")\n",
        "        try:\n",
        "          claims = parser.find('section', itemprop='claims').text\n",
        "          claims = clean_whitespace(''.join(filter(is_valid_char, claims)))\n",
        "          return temp_num, claims[claims.find(')')+1:].strip()\n",
        "        except:\n",
        "          if debug:\n",
        "            print(pub_num)\n",
        "          return np.nan, np.nan\n",
        "\n",
        "  if debug:\n",
        "    print(pub_num)\n",
        "  return np.nan, np.nan"
      ],
      "metadata": {
        "id": "tcm3yJYdJfja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oa_api_url = \"https://developer.uspto.gov/ds-api/oa_actions/v1/records\"\n",
        "headers = {'Content-Type': 'application/x-www-form-urlencoded', 'Accept': 'application/json'}\n",
        "\n",
        "for i, r in df.iterrows():\n",
        "  app_num = f\"{r['App_Number'][2:]}\"\n",
        "  app_num = '\"' + app_num + '\"'\n",
        "  data = {'criteria': f'patentApplicationNumber:{app_num}', 'start': '0', 'rows': '100'}\n",
        "  oa_search = requests.post(oa_api_url, headers=headers, data=data).json()\n",
        "  oa_response = oa_search['response']\n",
        "\n",
        "  if oa_response['numFound'] > 0:\n",
        "    j = 1\n",
        "    rej_nums = []\n",
        "    for oa in oa_response['docs']:\n",
        "      if 'sections.section102RejectionText' in oa.keys():\n",
        "        rej_text = oa['sections.section102RejectionText']\n",
        "        if rej_text == None:\n",
        "          continue\n",
        "\n",
        "        rej_text = rej_text[0][:250]\n",
        "        extract_num = text2text_generator(f\"question: What is the anticpated patent's publication number with country and kind code? context: {rej_text}\")[0]['generated_text']\n",
        "        rej_num = clean_pub_num(extract_num, debug=False)\n",
        "        if rej_num is not np.nan and rej_num not in rej_nums:\n",
        "          scrape_res = scrape_google_patents(rej_num, debug=True)\n",
        "          if scrape_res[0] is not np.nan:\n",
        "            df.loc[i, f'Rej_Pub_Number_{j}'], df.loc[i, f'Rej_Claims_{j}'] = scrape_res\n",
        "            j += 1\n",
        "            rej_nums.append(rej_num)"
      ],
      "metadata": {
        "id": "hCqys5mQlCoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATENT_COUNT_PER_ROW = 25\n",
        "\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "rej_cols = [col for col in list(df.columns) if col[:-1] == 'Rej_Claims_']\n",
        "non_rej_cols = []\n",
        "for i in range(1, PATENT_COUNT_PER_ROW+1):\n",
        "  non_rej_cols.extend([f'Pub_Number_{i}', f'Claims_{i}'])"
      ],
      "metadata": {
        "id": "qiE0ROizv845"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tot_result_count(term):\n",
        "  query_term = '%22' + term.lower() + '%22'\n",
        "  query_term.replace(' ', '%20')\n",
        "\n",
        "  bulk_data_api_url = f\"https://developer.uspto.gov/ibd-api/v1/application/publications?searchText={query_term}&rows=1&largeTextSearchFlag=Y\"\n",
        "  keyword_search = requests.get(bulk_data_api_url).json()\n",
        "  tot_result_count = keyword_search['recordTotalQuantity']\n",
        "\n",
        "  return tot_result_count\n",
        "\n",
        "def allocate_term_results(top_terms, tgt_patent_count, debug=False):\n",
        "  even_num_results = tgt_patent_count // len(top_terms)\n",
        "  term_result_alloc_dict = {term: [get_tot_result_count(term), even_num_results] for term in top_terms}\n",
        "  term_result_alloc_dict[top_terms[0]][1] += tgt_patent_count % len(top_terms)\n",
        "\n",
        "  master_key = 0\n",
        "  invalid_keys = []\n",
        "  for i, (tot_result_count, num_results) in enumerate(term_result_alloc_dict.values()):\n",
        "    if debug:\n",
        "      print(tot_result_count, num_results)\n",
        "      print(term_result_alloc_dict)\n",
        "\n",
        "    if tot_result_count <= 2*num_results:\n",
        "      temp_num_results = term_result_alloc_dict[top_terms[master_key]][1] + num_results\n",
        "      temp_tot_result = term_result_alloc_dict[top_terms[master_key]][0]\n",
        "      while temp_tot_result <= 2*temp_num_results:\n",
        "        master_key += 1\n",
        "        if master_key == len(top_terms):\n",
        "          # Return empty dict when not enough results found\n",
        "          return dict()\n",
        "        temp_num_results = term_result_alloc_dict[top_terms[master_key]][1] + num_results\n",
        "        temp_tot_result = term_result_alloc_dict[top_terms[master_key]][0]\n",
        "\n",
        "      term_result_alloc_dict[top_terms[master_key]][1] = temp_num_results\n",
        "      invalid_keys.append(i)\n",
        "\n",
        "  for key in invalid_keys:\n",
        "    del term_result_alloc_dict[top_terms[key]]\n",
        "\n",
        "  return term_result_alloc_dict"
      ],
      "metadata": {
        "id": "Ct3luJyZGAH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, r in df.iterrows():\n",
        "  top_terms = [term for term, score in kw_model.extract_keywords(r['Base_Abstract'], keyphrase_ngram_range=(1, 2))]\n",
        "  rej_count = len(rej_cols) - r[rej_cols].isna().sum()\n",
        "  tgt_patent_count = PATENT_COUNT_PER_ROW - rej_count\n",
        "\n",
        "  term_result_alloc_dict = allocate_term_results(top_terms, tgt_patent_count)\n",
        "\n",
        "  l = []\n",
        "  for term, (tot_result_count, num_results) in term_result_alloc_dict.items():\n",
        "    term = '%22' + term.lower() + '%22'\n",
        "    term.replace(' ', '%20')\n",
        "\n",
        "    start = random.randint(0, (tot_result_count - 2*num_results - 1))\n",
        "    bulk_data_api_url = f\"https://developer.uspto.gov/ibd-api/v1/application/publications?searchText={term}&start={start}&largeTextSearchFlag=Y\"\n",
        "    keyword_search = requests.get(bulk_data_api_url).json()\n",
        "\n",
        "    keyword_search_results = keyword_search['results']\n",
        "    j = 0\n",
        "    for result in keyword_search_results:\n",
        "      try:\n",
        "        pub_num = result['publicationDocumentIdentifier']\n",
        "        if pub_num == r['Base_Pub_Number'] or pub_num in l:\n",
        "          continue\n",
        "\n",
        "        claims = result['claimText'][0]\n",
        "        l.extend([pub_num, claims])\n",
        "        j += 1\n",
        "        if j == num_results:\n",
        "          break\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    if j != num_results:\n",
        "      print(f\"Retrieval error at row {i}\")\n",
        "\n",
        "    if len(l)/2 == tgt_patent_count:\n",
        "      if len(l)/2 != PATENT_COUNT_PER_ROW:\n",
        "        diff = (PATENT_COUNT_PER_ROW * 2) - len(l)\n",
        "        l.extend([np.nan]*diff)\n",
        "      df.loc[i, non_rej_cols] = l\n",
        "\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "G05qLRUtODO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Unnamed: 0', 'Rej_Pub_Number', 'Rej_Claims'], inplace=True)"
      ],
      "metadata": {
        "id": "w7e7RXZnsNOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('dataset.csv')"
      ],
      "metadata": {
        "id": "yE-Pg9IDsV12"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}